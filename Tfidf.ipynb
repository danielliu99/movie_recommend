{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1EQim8bAxNO_QVzUowr9lUrVsXyP9kF8-","authorship_tag":"ABX9TyMmWuezJUJWRQRszLyla7Jm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"C6vZ4RpDKTk2","executionInfo":{"status":"ok","timestamp":1682442046504,"user_tz":240,"elapsed":311,"user":{"displayName":"Ri Liu","userId":"09884916397611866241"}}},"outputs":[],"source":["import numpy as np "]},{"cell_type":"code","source":["## read the text vector from a file\n","\n","txt_vector = np.load('/content/drive/MyDrive/AdvancedPython/data/text_vector_mini.npy')\n","txt_vector.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l-tSHRoDKotQ","executionInfo":{"status":"ok","timestamp":1682442046768,"user_tz":240,"elapsed":2,"user":{"displayName":"Ri Liu","userId":"09884916397611866241"}},"outputId":"3b09b6a9-de95-4425-c9e2-e5f979580bd5"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1000, 1500)"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["$$\n","tfidf = tf \\cdot idf \\\\ \n","tf = \\frac{f_{t', d}}{\\sum_{t \\in d} f_{t', d}}, \\\\\n","where\\ f_{t', d} \\ is\\ the\\ number\\ of\\ times\\ that\\ term\\ t \\ occurs\\ in\\ an\\ overview\\ d \\\\ \n","idf = log (\\frac{N}{n_t}), \\\\\n","where\\ N\\ is\\ total\\ number\\ of\\ overviews\\ in\\ the\\ dataset\\ and\\ n_t\\ is\\ number\\ of\\ overviews\\ where\\ the\\ term\\ t\\ appears \n","$$"],"metadata":{"id":"2dvhfOGRS6K2"}},{"cell_type":"code","source":["def construct_tfidf(txt_vector): \n","\n","    ## word_num_col: word frequency of each word in all overviews (column-wise)\n","    ## iterate all columns, count how many rows are not zero\n","    word_num_col = [len(np.nonzero(txt_vector[:, i])[0]) for i in range(txt_vector.shape[1])]\n","    word_num_col = np.array(word_num_col, dtype=np.float32)\n","\n","    ## word_num_row: total word number in each overview (row-wise)\n","    ## iterate all rows, sum up all values in each row\n","    word_num_row = [np.sum(txt_vector[i, :]) for i in range(txt_vector.shape[0])]\n","    word_num_row = np.array(word_num_row, dtype=np.float32)[..., np.newaxis]\n","    \n","    ## idf: inverse document frequency matrix \n","    ## a word is common or rare across all overviews \n","    ## if a word is too common, then idf will be small to penalize the tf\n","    ## plus 1 to avoid denominator being 0\n","    idf = np.diag(np.log(txt_vector.shape[0] / (word_num_col + 1) ))\n","\n","    ## tf: term frequency matrix\n","    ## the number of times that term t occurs in a movie's overview\n","    tf = txt_vector / (word_num_row+1)\n","\n","    ## tfidf = tf * idf\n","    tfidf = np.dot(tf, idf)\n","\n","    return tfidf"],"metadata":{"id":"A7v59_wgNu0L","executionInfo":{"status":"ok","timestamp":1682442054099,"user_tz":240,"elapsed":603,"user":{"displayName":"Ri Liu","userId":"09884916397611866241"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["tfidf_matrix = construct_tfidf(txt_vector)\n","tfidf_matrix.shape"],"metadata":{"id":"KBxw-T10OrES","executionInfo":{"status":"ok","timestamp":1682439866102,"user_tz":240,"elapsed":134,"user":{"displayName":"Ri Liu","userId":"09884916397611866241"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["- Test runtime of the function"],"metadata":{"id":"o4CQTKbgStdU"}},{"cell_type":"code","source":["%timeit -n 100 construct_tfidf(txt_vector)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GW_t1CzGSlcz","executionInfo":{"status":"ok","timestamp":1682442117686,"user_tz":240,"elapsed":60374,"user":{"displayName":"Ri Liu","userId":"09884916397611866241"}},"outputId":"4c86c1cd-42be-4bf5-a7d8-2a25ea4b7acd"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["86 ms ± 5.82 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Z-MdqLsASn1i"},"execution_count":null,"outputs":[]}]}